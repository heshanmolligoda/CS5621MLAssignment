{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraies\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D,GaussianNoise, Input, UpSampling2D\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "#load mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#print data set\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise pixel values by first converting float and divide by maximum pixel values\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data into Categorical for that TF understands, there are 10 classes 0,1,2,3...9\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape train dataset and substract means \n",
    "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_sc_train = scaler.transform(x_train)\n",
    "x_sc_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative explained variance')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=500)\n",
    "pca.fit(x_train)\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 100)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=100)\n",
    "x_pca_train = pca.fit_transform(x_sc_train)\n",
    "x_pca_test = pca.transform(x_sc_test)\n",
    "pca_std = np.std(x_pca_train)\n",
    "\n",
    "print(x_sc_train.shape)\n",
    "print(x_pca_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_pca = pca.inverse_transform(x_pca_train)\n",
    "inv_sc = scaler.inverse_transform(inv_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential model\n",
    "model = Sequential()\n",
    "#desnse layer with 100 nodes\n",
    "model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(GaussianNoise(pca_std))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100, input_dim=100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 - 2s - loss: 0.6352 - accuracy: 0.8098 - val_loss: 0.2001 - val_accuracy: 0.9407\n",
      "Epoch 2/100\n",
      "1875/1875 - 2s - loss: 0.2932 - accuracy: 0.9134 - val_loss: 0.1667 - val_accuracy: 0.9514\n",
      "Epoch 3/100\n",
      "1875/1875 - 2s - loss: 0.2368 - accuracy: 0.9302 - val_loss: 0.1331 - val_accuracy: 0.9605\n",
      "Epoch 4/100\n",
      "1875/1875 - 2s - loss: 0.2076 - accuracy: 0.9407 - val_loss: 0.1198 - val_accuracy: 0.9656\n",
      "Epoch 5/100\n",
      "1875/1875 - 2s - loss: 0.1940 - accuracy: 0.9459 - val_loss: 0.1238 - val_accuracy: 0.9665\n",
      "Epoch 6/100\n",
      "1875/1875 - 2s - loss: 0.1804 - accuracy: 0.9502 - val_loss: 0.1224 - val_accuracy: 0.9667\n",
      "Epoch 7/100\n",
      "1875/1875 - 2s - loss: 0.1724 - accuracy: 0.9524 - val_loss: 0.1178 - val_accuracy: 0.9679\n",
      "Epoch 8/100\n",
      "1875/1875 - 2s - loss: 0.1659 - accuracy: 0.9551 - val_loss: 0.1178 - val_accuracy: 0.9705\n",
      "Epoch 9/100\n",
      "1875/1875 - 2s - loss: 0.1661 - accuracy: 0.9557 - val_loss: 0.1190 - val_accuracy: 0.9694\n",
      "Epoch 10/100\n",
      "1875/1875 - 2s - loss: 0.1621 - accuracy: 0.9578 - val_loss: 0.1227 - val_accuracy: 0.9710\n",
      "Epoch 11/100\n",
      "1875/1875 - 2s - loss: 0.1549 - accuracy: 0.9591 - val_loss: 0.1194 - val_accuracy: 0.9710\n",
      "Epoch 12/100\n",
      "1875/1875 - 2s - loss: 0.1547 - accuracy: 0.9603 - val_loss: 0.1334 - val_accuracy: 0.9715\n",
      "Epoch 13/100\n",
      "1875/1875 - 2s - loss: 0.1520 - accuracy: 0.9609 - val_loss: 0.1325 - val_accuracy: 0.9701\n",
      "Epoch 14/100\n",
      "1875/1875 - 2s - loss: 0.1540 - accuracy: 0.9603 - val_loss: 0.1306 - val_accuracy: 0.9710\n",
      "Epoch 15/100\n",
      "1875/1875 - 2s - loss: 0.1510 - accuracy: 0.9628 - val_loss: 0.1316 - val_accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "1875/1875 - 2s - loss: 0.1481 - accuracy: 0.9621 - val_loss: 0.1336 - val_accuracy: 0.9729\n",
      "Epoch 17/100\n",
      "1875/1875 - 2s - loss: 0.1498 - accuracy: 0.9637 - val_loss: 0.1423 - val_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "1875/1875 - 2s - loss: 0.1510 - accuracy: 0.9629 - val_loss: 0.1388 - val_accuracy: 0.9722\n",
      "Epoch 19/100\n",
      "1875/1875 - 2s - loss: 0.1508 - accuracy: 0.9645 - val_loss: 0.1385 - val_accuracy: 0.9745\n",
      "Epoch 20/100\n",
      "1875/1875 - 2s - loss: 0.1473 - accuracy: 0.9652 - val_loss: 0.1418 - val_accuracy: 0.9744\n",
      "Epoch 21/100\n",
      "1875/1875 - 2s - loss: 0.1464 - accuracy: 0.9657 - val_loss: 0.1502 - val_accuracy: 0.9743\n",
      "Epoch 22/100\n",
      "1875/1875 - 2s - loss: 0.1521 - accuracy: 0.9652 - val_loss: 0.1425 - val_accuracy: 0.9731\n",
      "Epoch 23/100\n",
      "1875/1875 - 2s - loss: 0.1455 - accuracy: 0.9663 - val_loss: 0.1618 - val_accuracy: 0.9734\n",
      "Epoch 24/100\n",
      "1875/1875 - 2s - loss: 0.1417 - accuracy: 0.9668 - val_loss: 0.1755 - val_accuracy: 0.9716\n",
      "Epoch 25/100\n",
      "1875/1875 - 2s - loss: 0.1496 - accuracy: 0.9670 - val_loss: 0.1797 - val_accuracy: 0.9749\n",
      "Epoch 26/100\n",
      "1875/1875 - 2s - loss: 0.1454 - accuracy: 0.9673 - val_loss: 0.1578 - val_accuracy: 0.9734\n",
      "Epoch 27/100\n",
      "1875/1875 - 2s - loss: 0.1441 - accuracy: 0.9679 - val_loss: 0.1639 - val_accuracy: 0.9738\n",
      "Epoch 28/100\n",
      "1875/1875 - 2s - loss: 0.1459 - accuracy: 0.9671 - val_loss: 0.1740 - val_accuracy: 0.9729\n",
      "Epoch 29/100\n",
      "1875/1875 - 2s - loss: 0.1471 - accuracy: 0.9673 - val_loss: 0.1571 - val_accuracy: 0.9745\n",
      "Epoch 30/100\n",
      "1875/1875 - 2s - loss: 0.1465 - accuracy: 0.9679 - val_loss: 0.1567 - val_accuracy: 0.9727\n",
      "Epoch 31/100\n",
      "1875/1875 - 2s - loss: 0.1497 - accuracy: 0.9675 - val_loss: 0.1652 - val_accuracy: 0.9725\n",
      "Epoch 32/100\n",
      "1875/1875 - 2s - loss: 0.1466 - accuracy: 0.9674 - val_loss: 0.1696 - val_accuracy: 0.9745\n",
      "Epoch 33/100\n",
      "1875/1875 - 2s - loss: 0.1456 - accuracy: 0.9696 - val_loss: 0.1617 - val_accuracy: 0.9758\n",
      "Epoch 34/100\n",
      "1875/1875 - 2s - loss: 0.1469 - accuracy: 0.9682 - val_loss: 0.1684 - val_accuracy: 0.9732\n",
      "Epoch 35/100\n",
      "1875/1875 - 2s - loss: 0.1492 - accuracy: 0.9686 - val_loss: 0.1621 - val_accuracy: 0.9737\n",
      "Epoch 36/100\n",
      "1875/1875 - 2s - loss: 0.1419 - accuracy: 0.9687 - val_loss: 0.1603 - val_accuracy: 0.9751\n",
      "Epoch 37/100\n",
      "1875/1875 - 2s - loss: 0.1469 - accuracy: 0.9688 - val_loss: 0.1739 - val_accuracy: 0.9740\n",
      "Epoch 38/100\n",
      "1875/1875 - 2s - loss: 0.1439 - accuracy: 0.9699 - val_loss: 0.1866 - val_accuracy: 0.9733\n",
      "Epoch 39/100\n",
      "1875/1875 - 2s - loss: 0.1546 - accuracy: 0.9689 - val_loss: 0.1912 - val_accuracy: 0.9729\n",
      "Epoch 40/100\n",
      "1875/1875 - 2s - loss: 0.1503 - accuracy: 0.9702 - val_loss: 0.1621 - val_accuracy: 0.9752\n",
      "Epoch 41/100\n",
      "1875/1875 - 2s - loss: 0.1506 - accuracy: 0.9692 - val_loss: 0.1904 - val_accuracy: 0.9734\n",
      "Epoch 42/100\n",
      "1875/1875 - 2s - loss: 0.1464 - accuracy: 0.9692 - val_loss: 0.2065 - val_accuracy: 0.9725\n",
      "Epoch 43/100\n",
      "1875/1875 - 2s - loss: 0.1465 - accuracy: 0.9700 - val_loss: 0.1821 - val_accuracy: 0.9715\n",
      "Epoch 44/100\n",
      "1875/1875 - 2s - loss: 0.1476 - accuracy: 0.9696 - val_loss: 0.1697 - val_accuracy: 0.9762\n",
      "Epoch 45/100\n",
      "1875/1875 - 2s - loss: 0.1507 - accuracy: 0.9700 - val_loss: 0.1754 - val_accuracy: 0.9740\n",
      "Epoch 46/100\n",
      "1875/1875 - 2s - loss: 0.1458 - accuracy: 0.9707 - val_loss: 0.1863 - val_accuracy: 0.9744\n",
      "Epoch 47/100\n",
      "1875/1875 - 2s - loss: 0.1480 - accuracy: 0.9702 - val_loss: 0.1776 - val_accuracy: 0.9747\n",
      "Epoch 48/100\n",
      "1875/1875 - 2s - loss: 0.1442 - accuracy: 0.9717 - val_loss: 0.1841 - val_accuracy: 0.9729\n",
      "Epoch 49/100\n",
      "1875/1875 - 2s - loss: 0.1430 - accuracy: 0.9703 - val_loss: 0.1874 - val_accuracy: 0.9730\n",
      "Epoch 50/100\n",
      "1875/1875 - 2s - loss: 0.1470 - accuracy: 0.9713 - val_loss: 0.2125 - val_accuracy: 0.9746\n",
      "Epoch 51/100\n",
      "1875/1875 - 2s - loss: 0.1533 - accuracy: 0.9699 - val_loss: 0.2260 - val_accuracy: 0.9758\n",
      "Epoch 52/100\n",
      "1875/1875 - 2s - loss: 0.1570 - accuracy: 0.9707 - val_loss: 0.1977 - val_accuracy: 0.9745\n",
      "Epoch 53/100\n",
      "1875/1875 - 2s - loss: 0.1443 - accuracy: 0.9715 - val_loss: 0.1945 - val_accuracy: 0.9718\n",
      "Epoch 54/100\n",
      "1875/1875 - 2s - loss: 0.1508 - accuracy: 0.9707 - val_loss: 0.1918 - val_accuracy: 0.9736\n",
      "Epoch 55/100\n",
      "1875/1875 - 2s - loss: 0.1521 - accuracy: 0.9709 - val_loss: 0.2006 - val_accuracy: 0.9740\n",
      "Epoch 56/100\n",
      "1875/1875 - 2s - loss: 0.1460 - accuracy: 0.9726 - val_loss: 0.1837 - val_accuracy: 0.9743\n",
      "Epoch 57/100\n",
      "1875/1875 - 2s - loss: 0.1547 - accuracy: 0.9708 - val_loss: 0.2196 - val_accuracy: 0.9722\n",
      "Epoch 58/100\n",
      "1875/1875 - 2s - loss: 0.1478 - accuracy: 0.9712 - val_loss: 0.2312 - val_accuracy: 0.9729\n",
      "Epoch 59/100\n",
      "1875/1875 - 2s - loss: 0.1452 - accuracy: 0.9716 - val_loss: 0.2101 - val_accuracy: 0.9726\n",
      "Epoch 60/100\n",
      "1875/1875 - 2s - loss: 0.1439 - accuracy: 0.9727 - val_loss: 0.2323 - val_accuracy: 0.9742\n",
      "Epoch 61/100\n",
      "1875/1875 - 2s - loss: 0.1500 - accuracy: 0.9715 - val_loss: 0.2092 - val_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "1875/1875 - 2s - loss: 0.1518 - accuracy: 0.9719 - val_loss: 0.2214 - val_accuracy: 0.9728\n",
      "Epoch 63/100\n",
      "1875/1875 - 2s - loss: 0.1519 - accuracy: 0.9719 - val_loss: 0.2305 - val_accuracy: 0.9750\n",
      "Epoch 64/100\n",
      "1875/1875 - 2s - loss: 0.1507 - accuracy: 0.9722 - val_loss: 0.2310 - val_accuracy: 0.9748\n",
      "Epoch 65/100\n",
      "1875/1875 - 2s - loss: 0.1481 - accuracy: 0.9731 - val_loss: 0.2138 - val_accuracy: 0.9737\n",
      "Epoch 66/100\n",
      "1875/1875 - 2s - loss: 0.1561 - accuracy: 0.9725 - val_loss: 0.2034 - val_accuracy: 0.9728\n",
      "Epoch 67/100\n",
      "1875/1875 - 2s - loss: 0.1538 - accuracy: 0.9722 - val_loss: 0.2289 - val_accuracy: 0.9753\n",
      "Epoch 68/100\n",
      "1875/1875 - 2s - loss: 0.1545 - accuracy: 0.9711 - val_loss: 0.2309 - val_accuracy: 0.9733\n",
      "Epoch 69/100\n",
      "1875/1875 - 2s - loss: 0.1529 - accuracy: 0.9718 - val_loss: 0.2379 - val_accuracy: 0.9745\n",
      "Epoch 70/100\n",
      "1875/1875 - 2s - loss: 0.1464 - accuracy: 0.9728 - val_loss: 0.2335 - val_accuracy: 0.9739\n",
      "Epoch 71/100\n",
      "1875/1875 - 2s - loss: 0.1445 - accuracy: 0.9741 - val_loss: 0.2605 - val_accuracy: 0.9749\n",
      "Epoch 72/100\n",
      "1875/1875 - 2s - loss: 0.1625 - accuracy: 0.9722 - val_loss: 0.2376 - val_accuracy: 0.9746\n",
      "Epoch 73/100\n",
      "1875/1875 - 2s - loss: 0.1485 - accuracy: 0.9727 - val_loss: 0.2331 - val_accuracy: 0.9737\n",
      "Epoch 74/100\n",
      "1875/1875 - 2s - loss: 0.1488 - accuracy: 0.9722 - val_loss: 0.2119 - val_accuracy: 0.9749\n",
      "Epoch 75/100\n",
      "1875/1875 - 2s - loss: 0.1603 - accuracy: 0.9730 - val_loss: 0.2264 - val_accuracy: 0.9767\n",
      "Epoch 76/100\n",
      "1875/1875 - 2s - loss: 0.1486 - accuracy: 0.9743 - val_loss: 0.2291 - val_accuracy: 0.9756\n",
      "Epoch 77/100\n",
      "1875/1875 - 2s - loss: 0.1498 - accuracy: 0.9734 - val_loss: 0.2715 - val_accuracy: 0.9740\n",
      "Epoch 78/100\n",
      "1875/1875 - 2s - loss: 0.1518 - accuracy: 0.9731 - val_loss: 0.2707 - val_accuracy: 0.9745\n",
      "Epoch 79/100\n",
      "1875/1875 - 2s - loss: 0.1572 - accuracy: 0.9736 - val_loss: 0.2571 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "1875/1875 - 2s - loss: 0.1487 - accuracy: 0.9738 - val_loss: 0.2418 - val_accuracy: 0.9760\n",
      "Epoch 81/100\n",
      "1875/1875 - 2s - loss: 0.1589 - accuracy: 0.9732 - val_loss: 0.2585 - val_accuracy: 0.9758\n",
      "Epoch 82/100\n",
      "1875/1875 - 2s - loss: 0.1544 - accuracy: 0.9736 - val_loss: 0.2352 - val_accuracy: 0.9734\n",
      "Epoch 83/100\n",
      "1875/1875 - 2s - loss: 0.1481 - accuracy: 0.9735 - val_loss: 0.2377 - val_accuracy: 0.9742\n",
      "Epoch 84/100\n",
      "1875/1875 - 2s - loss: 0.1512 - accuracy: 0.9739 - val_loss: 0.2522 - val_accuracy: 0.9745\n",
      "Epoch 85/100\n",
      "1875/1875 - 2s - loss: 0.1579 - accuracy: 0.9728 - val_loss: 0.2631 - val_accuracy: 0.9740\n",
      "Epoch 86/100\n",
      "1875/1875 - 2s - loss: 0.1484 - accuracy: 0.9743 - val_loss: 0.2555 - val_accuracy: 0.9756\n",
      "Epoch 87/100\n",
      "1875/1875 - 2s - loss: 0.1477 - accuracy: 0.9746 - val_loss: 0.2690 - val_accuracy: 0.9739\n",
      "Epoch 88/100\n",
      "1875/1875 - 2s - loss: 0.1539 - accuracy: 0.9749 - val_loss: 0.2160 - val_accuracy: 0.9766\n",
      "Epoch 89/100\n",
      "1875/1875 - 2s - loss: 0.1651 - accuracy: 0.9744 - val_loss: 0.2637 - val_accuracy: 0.9738\n",
      "Epoch 90/100\n",
      "1875/1875 - 2s - loss: 0.1539 - accuracy: 0.9753 - val_loss: 0.2447 - val_accuracy: 0.9761\n",
      "Epoch 91/100\n",
      "1875/1875 - 2s - loss: 0.1580 - accuracy: 0.9746 - val_loss: 0.2286 - val_accuracy: 0.9770\n",
      "Epoch 92/100\n",
      "1875/1875 - 2s - loss: 0.1640 - accuracy: 0.9739 - val_loss: 0.2390 - val_accuracy: 0.9745\n",
      "Epoch 93/100\n",
      "1875/1875 - 2s - loss: 0.1591 - accuracy: 0.9743 - val_loss: 0.2655 - val_accuracy: 0.9747\n",
      "Epoch 94/100\n",
      "1875/1875 - 2s - loss: 0.1529 - accuracy: 0.9743 - val_loss: 0.2495 - val_accuracy: 0.9748\n",
      "Epoch 95/100\n",
      "1875/1875 - 2s - loss: 0.1529 - accuracy: 0.9743 - val_loss: 0.2753 - val_accuracy: 0.9754\n",
      "Epoch 96/100\n",
      "1875/1875 - 2s - loss: 0.1564 - accuracy: 0.9742 - val_loss: 0.2473 - val_accuracy: 0.9757\n",
      "Epoch 97/100\n",
      "1875/1875 - 2s - loss: 0.1556 - accuracy: 0.9751 - val_loss: 0.2461 - val_accuracy: 0.9766\n",
      "Epoch 98/100\n",
      "1875/1875 - 2s - loss: 0.1534 - accuracy: 0.9745 - val_loss: 0.2501 - val_accuracy: 0.9737\n",
      "Epoch 99/100\n",
      "1875/1875 - 2s - loss: 0.1561 - accuracy: 0.9750 - val_loss: 0.2929 - val_accuracy: 0.9748\n",
      "Epoch 100/100\n",
      "1875/1875 - 2s - loss: 0.1666 - accuracy: 0.9742 - val_loss: 0.3043 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243a3447948>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_pca_train, y_train, epochs=100, batch_size=32, validation_data=(x_pca_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "#load mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#print data set\n",
    "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
    "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Images are of size 28x28 and images are gray scale, lets reshape arrays to have single color channel\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test  = x_test.reshape((x_test.shape[0], 28, 28, 1))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise pixel values by first converting float and divide by maximum pixel values\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "encoder = Sequential()\n",
    "encoder.add(Conv2D(16, (3, 3), activation='relu', padding='same',\n",
    "                   input_shape=(28,28,1)))\n",
    "encoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "encoder.add(MaxPooling2D((2, 2), padding='same'))\n",
    "encoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "encoder.add(MaxPooling2D((4, 4), padding='same'))\n",
    "encoder.add(Conv2D(8, (1, 1), activation='sigmoid', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "decoder = Sequential()\n",
    "decoder.add(Conv2D(8, (3, 3), activation='relu', padding='same',\n",
    "                   input_shape=encoder.output_shape[1:]))\n",
    "decoder.add(UpSampling2D((4, 4)))\n",
    "decoder.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "decoder.add(UpSampling2D((2, 2)))\n",
    "decoder.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "decoder.add(UpSampling2D((2, 2)))\n",
    "decoder.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(encoder)\n",
    "autoencoder.add(decoder)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 36s 307ms/step - loss: 0.3914 - val_loss: 0.3936\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 41s 351ms/step - loss: 0.3892 - val_loss: 0.3913\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 40s 341ms/step - loss: 0.3870 - val_loss: 0.3890\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 41s 348ms/step - loss: 0.3847 - val_loss: 0.3868\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.3827 - val_loss: 0.3848\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.3807 - val_loss: 0.3828\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 46s 391ms/step - loss: 0.3787 - val_loss: 0.3807\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 48s 406ms/step - loss: 0.3767 - val_loss: 0.3788\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 40s 339ms/step - loss: 0.3748 - val_loss: 0.3768\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3729 - val_loss: 0.3748\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 40s 338ms/step - loss: 0.3709 - val_loss: 0.3728\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3688 - val_loss: 0.3707\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 40s 341ms/step - loss: 0.3668 - val_loss: 0.3685\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.3647 - val_loss: 0.3664\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 41s 349ms/step - loss: 0.3626 - val_loss: 0.3642\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3604 - val_loss: 0.3620\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.3583 - val_loss: 0.3598\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.3562 - val_loss: 0.3578\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 40s 341ms/step - loss: 0.3542 - val_loss: 0.3557\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3521 - val_loss: 0.3536\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3501 - val_loss: 0.3515\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3481 - val_loss: 0.3495\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.3461 - val_loss: 0.3475\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 42s 357ms/step - loss: 0.3442 - val_loss: 0.3456\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 41s 346ms/step - loss: 0.3423 - val_loss: 0.3437\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3405 - val_loss: 0.3419\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 39s 334ms/step - loss: 0.3387 - val_loss: 0.3401\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 40s 336ms/step - loss: 0.3370 - val_loss: 0.3382\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 39s 332ms/step - loss: 0.3352 - val_loss: 0.3364\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.3334 - val_loss: 0.3347\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 38s 321ms/step - loss: 0.3318 - val_loss: 0.3330\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 38s 326ms/step - loss: 0.3302 - val_loss: 0.3313\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3286 - val_loss: 0.3297\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3271 - val_loss: 0.3282\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 39s 332ms/step - loss: 0.3256 - val_loss: 0.3267\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3242 - val_loss: 0.3253\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 39s 329ms/step - loss: 0.3229 - val_loss: 0.3240\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 39s 327ms/step - loss: 0.3216 - val_loss: 0.3227\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3204 - val_loss: 0.3215\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 41s 346ms/step - loss: 0.3192 - val_loss: 0.3203\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 38s 322ms/step - loss: 0.3181 - val_loss: 0.3192\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3170 - val_loss: 0.3181\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 38s 322ms/step - loss: 0.3159 - val_loss: 0.3169\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3149 - val_loss: 0.3159\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 38s 321ms/step - loss: 0.3138 - val_loss: 0.3148\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 38s 321ms/step - loss: 0.3129 - val_loss: 0.3139\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 38s 323ms/step - loss: 0.3119 - val_loss: 0.3129\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 38s 325ms/step - loss: 0.3110 - val_loss: 0.3120\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 42s 352ms/step - loss: 0.3101 - val_loss: 0.3110\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3092 - val_loss: 0.3101\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3084 - val_loss: 0.3094\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3077 - val_loss: 0.3086\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 43s 360ms/step - loss: 0.3070 - val_loss: 0.3079\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.3062 - val_loss: 0.3071\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 40s 340ms/step - loss: 0.3055 - val_loss: 0.3064\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 40s 341ms/step - loss: 0.3048 - val_loss: 0.3057\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 42s 360ms/step - loss: 0.3041 - val_loss: 0.3050\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 41s 351ms/step - loss: 0.3035 - val_loss: 0.3044\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 41s 343ms/step - loss: 0.3029 - val_loss: 0.3038\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.3023 - val_loss: 0.3032\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.3018 - val_loss: 0.3027\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.3013 - val_loss: 0.3022\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.3008 - val_loss: 0.3017\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 40s 343ms/step - loss: 0.3004 - val_loss: 0.3013\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.2999 - val_loss: 0.3008\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 41s 349ms/step - loss: 0.2995 - val_loss: 0.3004\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.2991 - val_loss: 0.3000\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 41s 349ms/step - loss: 0.2987 - val_loss: 0.2995\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 41s 344ms/step - loss: 0.2982 - val_loss: 0.2991\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 42s 358ms/step - loss: 0.2978 - val_loss: 0.2987\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 44s 373ms/step - loss: 0.2974 - val_loss: 0.2983\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 53s 451ms/step - loss: 0.2970 - val_loss: 0.2979\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 53s 452ms/step - loss: 0.2967 - val_loss: 0.2975\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 53s 450ms/step - loss: 0.2963 - val_loss: 0.2972\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 54s 458ms/step - loss: 0.2960 - val_loss: 0.2968\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 54s 456ms/step - loss: 0.2956 - val_loss: 0.2965\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 54s 455ms/step - loss: 0.2953 - val_loss: 0.2961\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 54s 461ms/step - loss: 0.2950 - val_loss: 0.2958\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 54s 461ms/step - loss: 0.2946 - val_loss: 0.2955\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 54s 460ms/step - loss: 0.2943 - val_loss: 0.2951\n",
      "Epoch 81/100\n",
      "118/118 [==============================] - 52s 439ms/step - loss: 0.2940 - val_loss: 0.2948\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 53s 452ms/step - loss: 0.2937 - val_loss: 0.2945\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 54s 461ms/step - loss: 0.2934 - val_loss: 0.2942\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 55s 464ms/step - loss: 0.2931 - val_loss: 0.2939\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 55s 468ms/step - loss: 0.2928 - val_loss: 0.2936\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 56s 472ms/step - loss: 0.2925 - val_loss: 0.2933\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 56s 474ms/step - loss: 0.2922 - val_loss: 0.2930\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 56s 478ms/step - loss: 0.2919 - val_loss: 0.2927\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 56s 476ms/step - loss: 0.2916 - val_loss: 0.2924\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 56s 474ms/step - loss: 0.2913 - val_loss: 0.2921\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 57s 479ms/step - loss: 0.2910 - val_loss: 0.2918\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 57s 481ms/step - loss: 0.2907 - val_loss: 0.2915\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 56s 475ms/step - loss: 0.2904 - val_loss: 0.2911\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 58s 489ms/step - loss: 0.2901 - val_loss: 0.2908\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 57s 480ms/step - loss: 0.2899 - val_loss: 0.2906\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 57s 487ms/step - loss: 0.2896 - val_loss: 0.2903\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 58s 495ms/step - loss: 0.2893 - val_loss: 0.2900\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 58s 493ms/step - loss: 0.2891 - val_loss: 0.2898\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 57s 485ms/step - loss: 0.2888 - val_loss: 0.2895\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 40s 342ms/step - loss: 0.2886 - val_loss: 0.2893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243a4c29d08>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train, epochs=100,\n",
    "                    batch_size=512,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
